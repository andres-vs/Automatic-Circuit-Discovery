{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "UhpchJJoL3GM",
   "metadata": {
    "id": "UhpchJJoL3GM"
   },
   "outputs": [],
   "source": [
    "MODEL_NAME = \"andres-vs/bert-base-uncased-finetuned_Att-Noneg-depth0\"\n",
    "NEXAMPLES = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64fbde95",
   "metadata": {
    "id": "64fbde95"
   },
   "source": [
    "<h1>ACDC Main Demo</h1>\n",
    "\n",
    "<p>This notebook (which doubles as a script) shows several use cases of ACDC</p>\n",
    "\n",
    "<p>The codebase is built on top of https://github.com/neelnanda-io/TransformerLens (source version)</p>\n",
    "\n",
    "<h3>Setup:</h3>\n",
    "<p>Janky code to do different setup when run in a Colab notebook vs VSCode (adapted from e.g <a href=\"https://github.com/neelnanda-io/TransformerLens/blob/5c89b7583e73ce96db5e46ef86a14b15f303dde6/demos/Activation_Patching_in_TL_Demo.ipynb\">this notebook</a>)</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "KTtxPLnnLmcl",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KTtxPLnnLmcl",
    "outputId": "7817682c-3d27-4217-b321-8f3a51095115"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mandresvanschel\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    }
   ],
   "source": [
    "!wandb login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "99cb926c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "99cb926c",
    "outputId": "142749e9-1804-4f51-e0b1-17c57abc0b27"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No module named 'google.colab'\n",
      "Running outside of colab\n",
      "Running as a notebook\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    import google.colab\n",
    "\n",
    "    IN_COLAB = True\n",
    "    print(\"Running as a Colab notebook\")\n",
    "\n",
    "    import subprocess # to install graphviz dependencies\n",
    "    command = ['apt-get', 'install', 'graphviz-dev']\n",
    "    subprocess.run(command, check=True)\n",
    "\n",
    "    import os # make images folder\n",
    "    os.mkdir(\"ims/\")\n",
    "\n",
    "    from IPython import get_ipython\n",
    "    ipython = get_ipython()\n",
    "\n",
    "    ipython.run_line_magic( # install ACDC\n",
    "        \"pip\",\n",
    "        \"install git+https://github.com/andres-vs/Automatic-Circuit-Discovery.git@b8b5bee90a6d501c195e75596cd3c93f13033b5d\",\n",
    "    )\n",
    "\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "    IN_COLAB = False\n",
    "    print(\"Running outside of colab\")\n",
    "\n",
    "    import numpy # crucial to not get cursed error\n",
    "    import plotly\n",
    "\n",
    "    plotly.io.renderers.default = \"colab\"  # added by Arthur so running as a .py notebook with #%% generates .ipynb notebooks that display in colab\n",
    "    # disable this option when developing rather than generating notebook outputs\n",
    "\n",
    "    import os # make images folder\n",
    "    if not os.path.exists(\"ims/\"):\n",
    "        os.mkdir(\"ims/\")\n",
    "\n",
    "    from IPython import get_ipython\n",
    "\n",
    "    ipython = get_ipython()\n",
    "    if ipython is not None:\n",
    "        print(\"Running as a notebook\")\n",
    "        ipython.run_line_magic(\"load_ext\", \"autoreload\")  # type: ignore\n",
    "        ipython.run_line_magic(\"autoreload\", \"2\")  # type: ignore\n",
    "    else:\n",
    "        print(\"Running as a script\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "SUH3421lmdLS",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SUH3421lmdLS",
    "outputId": "13987bd8-1cea-4652-cd69-2c3f306ec823"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/andres-vs/TransformerLens.git@61caa4ccba262131860bd7c587aaa1171e283d22\n",
      "  Cloning https://github.com/andres-vs/TransformerLens.git (to revision 61caa4ccba262131860bd7c587aaa1171e283d22) to /tmp/pip-req-build-pf_nwxck\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/andres-vs/TransformerLens.git /tmp/pip-req-build-pf_nwxck\n",
      "  Running command git rev-parse -q --verify 'sha^61caa4ccba262131860bd7c587aaa1171e283d22'\n",
      "  Running command git fetch -q https://github.com/andres-vs/TransformerLens.git 61caa4ccba262131860bd7c587aaa1171e283d22\n",
      "  Resolved https://github.com/andres-vs/TransformerLens.git to commit 61caa4ccba262131860bd7c587aaa1171e283d22\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: accelerate>=0.23.0 in /home/andres/.local/lib/python3.10/site-packages (from transformer-lens==0.0.0) (0.28.0)\n",
      "Requirement already satisfied: beartype<0.15.0,>=0.14.1 in /home/andres/.local/lib/python3.10/site-packages (from transformer-lens==0.0.0) (0.14.1)\n",
      "Requirement already satisfied: better-abc<0.0.4,>=0.0.3 in /home/andres/.local/lib/python3.10/site-packages (from transformer-lens==0.0.0) (0.0.3)\n",
      "Requirement already satisfied: datasets>=2.7.1 in /home/andres/.local/lib/python3.10/site-packages (from transformer-lens==0.0.0) (2.18.0)\n",
      "Requirement already satisfied: einops>=0.6.0 in /home/andres/.local/lib/python3.10/site-packages (from transformer-lens==0.0.0) (0.7.0)\n",
      "Requirement already satisfied: fancy-einsum>=0.0.3 in /home/andres/.local/lib/python3.10/site-packages (from transformer-lens==0.0.0) (0.0.3)\n",
      "Requirement already satisfied: jaxtyping>=0.2.11 in /home/andres/.local/lib/python3.10/site-packages (from transformer-lens==0.0.0) (0.2.28)\n",
      "Requirement already satisfied: numpy>=1.24 in /home/andres/.local/lib/python3.10/site-packages (from transformer-lens==0.0.0) (1.26.4)\n",
      "Requirement already satisfied: pandas>=1.1.5 in /home/andres/miniconda3/envs/acdc/lib/python3.10/site-packages (from transformer-lens==0.0.0) (2.0.3)\n",
      "Requirement already satisfied: rich>=12.6.0 in /home/andres/.local/lib/python3.10/site-packages (from transformer-lens==0.0.0) (13.7.1)\n",
      "Requirement already satisfied: sentencepiece in /home/andres/miniconda3/envs/acdc/lib/python3.10/site-packages (from transformer-lens==0.0.0) (0.2.0)\n",
      "Requirement already satisfied: torch>=1.10 in /home/andres/.local/lib/python3.10/site-packages (from transformer-lens==0.0.0) (2.2.1)\n",
      "Requirement already satisfied: tqdm>=4.64.1 in /home/andres/.local/lib/python3.10/site-packages (from transformer-lens==0.0.0) (4.66.2)\n",
      "Requirement already satisfied: transformers>=4.37.2 in /home/andres/.local/lib/python3.10/site-packages (from transformer-lens==0.0.0) (4.38.2)\n",
      "Requirement already satisfied: typing-extensions in /home/andres/.local/lib/python3.10/site-packages (from transformer-lens==0.0.0) (4.10.0)\n",
      "Requirement already satisfied: wandb>=0.13.5 in /home/andres/.local/lib/python3.10/site-packages (from transformer-lens==0.0.0) (0.16.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/andres/.local/lib/python3.10/site-packages (from accelerate>=0.23.0->transformer-lens==0.0.0) (24.0)\n",
      "Requirement already satisfied: psutil in /home/andres/.local/lib/python3.10/site-packages (from accelerate>=0.23.0->transformer-lens==0.0.0) (5.9.8)\n",
      "Requirement already satisfied: pyyaml in /home/andres/miniconda3/envs/acdc/lib/python3.10/site-packages (from accelerate>=0.23.0->transformer-lens==0.0.0) (6.0.1)\n",
      "Requirement already satisfied: huggingface-hub in /home/andres/.local/lib/python3.10/site-packages (from accelerate>=0.23.0->transformer-lens==0.0.0) (0.21.4)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /home/andres/.local/lib/python3.10/site-packages (from accelerate>=0.23.0->transformer-lens==0.0.0) (0.4.2)\n",
      "Requirement already satisfied: filelock in /home/andres/.local/lib/python3.10/site-packages (from datasets>=2.7.1->transformer-lens==0.0.0) (3.13.1)\n",
      "Requirement already satisfied: pyarrow>=12.0.0 in /home/andres/.local/lib/python3.10/site-packages (from datasets>=2.7.1->transformer-lens==0.0.0) (15.0.1)\n",
      "Requirement already satisfied: pyarrow-hotfix in /home/andres/.local/lib/python3.10/site-packages (from datasets>=2.7.1->transformer-lens==0.0.0) (0.6)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /home/andres/.local/lib/python3.10/site-packages (from datasets>=2.7.1->transformer-lens==0.0.0) (0.3.8)\n",
      "Requirement already satisfied: requests>=2.19.0 in /home/andres/.local/lib/python3.10/site-packages (from datasets>=2.7.1->transformer-lens==0.0.0) (2.31.0)\n",
      "Requirement already satisfied: xxhash in /home/andres/.local/lib/python3.10/site-packages (from datasets>=2.7.1->transformer-lens==0.0.0) (3.4.1)\n",
      "Requirement already satisfied: multiprocess in /home/andres/.local/lib/python3.10/site-packages (from datasets>=2.7.1->transformer-lens==0.0.0) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2024.2.0,>=2023.1.0 in /home/andres/.local/lib/python3.10/site-packages (from fsspec[http]<=2024.2.0,>=2023.1.0->datasets>=2.7.1->transformer-lens==0.0.0) (2024.2.0)\n",
      "Requirement already satisfied: aiohttp in /home/andres/.local/lib/python3.10/site-packages (from datasets>=2.7.1->transformer-lens==0.0.0) (3.9.3)\n",
      "Requirement already satisfied: typeguard==2.13.3 in /home/andres/.local/lib/python3.10/site-packages (from jaxtyping>=0.2.11->transformer-lens==0.0.0) (2.13.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/andres/.local/lib/python3.10/site-packages (from pandas>=1.1.5->transformer-lens==0.0.0) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/andres/.local/lib/python3.10/site-packages (from pandas>=1.1.5->transformer-lens==0.0.0) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /home/andres/.local/lib/python3.10/site-packages (from pandas>=1.1.5->transformer-lens==0.0.0) (2024.1)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /home/andres/.local/lib/python3.10/site-packages (from rich>=12.6.0->transformer-lens==0.0.0) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /home/andres/.local/lib/python3.10/site-packages (from rich>=12.6.0->transformer-lens==0.0.0) (2.17.2)\n",
      "Requirement already satisfied: sympy in /home/andres/.local/lib/python3.10/site-packages (from torch>=1.10->transformer-lens==0.0.0) (1.12)\n",
      "Requirement already satisfied: networkx in /home/andres/.local/lib/python3.10/site-packages (from torch>=1.10->transformer-lens==0.0.0) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /home/andres/.local/lib/python3.10/site-packages (from torch>=1.10->transformer-lens==0.0.0) (3.1.3)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /home/andres/.local/lib/python3.10/site-packages (from torch>=1.10->transformer-lens==0.0.0) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /home/andres/.local/lib/python3.10/site-packages (from torch>=1.10->transformer-lens==0.0.0) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /home/andres/.local/lib/python3.10/site-packages (from torch>=1.10->transformer-lens==0.0.0) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /home/andres/.local/lib/python3.10/site-packages (from torch>=1.10->transformer-lens==0.0.0) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /home/andres/.local/lib/python3.10/site-packages (from torch>=1.10->transformer-lens==0.0.0) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /home/andres/.local/lib/python3.10/site-packages (from torch>=1.10->transformer-lens==0.0.0) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /home/andres/.local/lib/python3.10/site-packages (from torch>=1.10->transformer-lens==0.0.0) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /home/andres/.local/lib/python3.10/site-packages (from torch>=1.10->transformer-lens==0.0.0) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /home/andres/.local/lib/python3.10/site-packages (from torch>=1.10->transformer-lens==0.0.0) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /home/andres/.local/lib/python3.10/site-packages (from torch>=1.10->transformer-lens==0.0.0) (2.19.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /home/andres/.local/lib/python3.10/site-packages (from torch>=1.10->transformer-lens==0.0.0) (12.1.105)\n",
      "Requirement already satisfied: triton==2.2.0 in /home/andres/.local/lib/python3.10/site-packages (from torch>=1.10->transformer-lens==0.0.0) (2.2.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /home/andres/.local/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.10->transformer-lens==0.0.0) (12.4.99)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/andres/.local/lib/python3.10/site-packages (from transformers>=4.37.2->transformer-lens==0.0.0) (2023.12.25)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in /home/andres/.local/lib/python3.10/site-packages (from transformers>=4.37.2->transformer-lens==0.0.0) (0.15.2)\n",
      "Requirement already satisfied: Click!=8.0.0,>=7.1 in /home/andres/.local/lib/python3.10/site-packages (from wandb>=0.13.5->transformer-lens==0.0.0) (8.1.7)\n",
      "Requirement already satisfied: GitPython!=3.1.29,>=1.0.0 in /home/andres/.local/lib/python3.10/site-packages (from wandb>=0.13.5->transformer-lens==0.0.0) (3.1.42)\n",
      "Requirement already satisfied: sentry-sdk>=1.0.0 in /home/andres/.local/lib/python3.10/site-packages (from wandb>=0.13.5->transformer-lens==0.0.0) (1.42.0)\n",
      "Requirement already satisfied: docker-pycreds>=0.4.0 in /home/andres/.local/lib/python3.10/site-packages (from wandb>=0.13.5->transformer-lens==0.0.0) (0.4.0)\n",
      "Requirement already satisfied: setproctitle in /home/andres/.local/lib/python3.10/site-packages (from wandb>=0.13.5->transformer-lens==0.0.0) (1.3.3)\n",
      "Requirement already satisfied: setuptools in /home/andres/miniconda3/envs/acdc/lib/python3.10/site-packages (from wandb>=0.13.5->transformer-lens==0.0.0) (68.2.2)\n",
      "Requirement already satisfied: appdirs>=1.4.3 in /home/andres/.local/lib/python3.10/site-packages (from wandb>=0.13.5->transformer-lens==0.0.0) (1.4.4)\n",
      "Requirement already satisfied: protobuf!=4.21.0,<5,>=3.19.0 in /home/andres/.local/lib/python3.10/site-packages (from wandb>=0.13.5->transformer-lens==0.0.0) (4.25.3)\n",
      "Requirement already satisfied: six>=1.4.0 in /home/andres/miniconda3/envs/acdc/lib/python3.10/site-packages (from docker-pycreds>=0.4.0->wandb>=0.13.5->transformer-lens==0.0.0) (1.16.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/andres/.local/lib/python3.10/site-packages (from aiohttp->datasets>=2.7.1->transformer-lens==0.0.0) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/andres/.local/lib/python3.10/site-packages (from aiohttp->datasets>=2.7.1->transformer-lens==0.0.0) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/andres/.local/lib/python3.10/site-packages (from aiohttp->datasets>=2.7.1->transformer-lens==0.0.0) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/andres/.local/lib/python3.10/site-packages (from aiohttp->datasets>=2.7.1->transformer-lens==0.0.0) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /home/andres/.local/lib/python3.10/site-packages (from aiohttp->datasets>=2.7.1->transformer-lens==0.0.0) (1.9.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /home/andres/.local/lib/python3.10/site-packages (from aiohttp->datasets>=2.7.1->transformer-lens==0.0.0) (4.0.3)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /home/andres/.local/lib/python3.10/site-packages (from GitPython!=3.1.29,>=1.0.0->wandb>=0.13.5->transformer-lens==0.0.0) (4.0.11)\n",
      "Requirement already satisfied: mdurl~=0.1 in /home/andres/.local/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich>=12.6.0->transformer-lens==0.0.0) (0.1.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/andres/.local/lib/python3.10/site-packages (from requests>=2.19.0->datasets>=2.7.1->transformer-lens==0.0.0) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/andres/.local/lib/python3.10/site-packages (from requests>=2.19.0->datasets>=2.7.1->transformer-lens==0.0.0) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/andres/.local/lib/python3.10/site-packages (from requests>=2.19.0->datasets>=2.7.1->transformer-lens==0.0.0) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/andres/.local/lib/python3.10/site-packages (from requests>=2.19.0->datasets>=2.7.1->transformer-lens==0.0.0) (2024.2.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/andres/.local/lib/python3.10/site-packages (from jinja2->torch>=1.10->transformer-lens==0.0.0) (2.1.5)\n",
      "Requirement already satisfied: mpmath>=0.19 in /home/andres/.local/lib/python3.10/site-packages (from sympy->torch>=1.10->transformer-lens==0.0.0) (1.3.0)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /home/andres/.local/lib/python3.10/site-packages (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb>=0.13.5->transformer-lens==0.0.0) (5.0.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "ipython.run_line_magic( # install custom transformerlens library\n",
    "        \"pip\",\n",
    "        \"install git+https://github.com/andres-vs/TransformerLens.git@61caa4ccba262131860bd7c587aaa1171e283d22\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d46fa914",
   "metadata": {
    "id": "d46fa914"
   },
   "source": [
    "<h2>Imports etc</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "945274fc",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "945274fc",
    "outputId": "5d1d30af-8b1d-4298-9954-074f46bbc28a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<torch.autograd.grad_mode.set_grad_enabled at 0x7fcb4dac38b0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wandb\n",
    "import IPython\n",
    "from IPython.display import Image, display\n",
    "import torch\n",
    "import gc\n",
    "from tqdm import tqdm\n",
    "import networkx as nx\n",
    "import os\n",
    "import torch\n",
    "import huggingface_hub\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import einops\n",
    "from tqdm import tqdm\n",
    "import yaml\n",
    "from transformers import AutoModelForCausalLM, AutoConfig, AutoTokenizer\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "import plotly.io as pio\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "from transformer_lens.hook_points import HookedRootModule, HookPoint\n",
    "from transformer_lens.HookedTransformer import (\n",
    "    HookedTransformer,\n",
    ")\n",
    "try:\n",
    "    from acdc.tracr_task.utils import (\n",
    "        get_all_tracr_things,\n",
    "        get_tracr_model_input_and_tl_model,\n",
    "    )\n",
    "except Exception as e:\n",
    "    print(f\"Could not import `tracr` because {e}; the rest of the file should work but you cannot use the tracr tasks\")\n",
    "from acdc.docstring.utils import get_all_docstring_things\n",
    "from acdc.acdc_utils import (\n",
    "    make_nd_dict,\n",
    "    reset_network,\n",
    "    shuffle_tensor,\n",
    "    cleanup,\n",
    "    ct,\n",
    "    TorchIndex,\n",
    "    Edge,\n",
    "    EdgeType,\n",
    ")  # these introduce several important classes !!!\n",
    "\n",
    "from acdc.TLACDCCorrespondence import TLACDCCorrespondence\n",
    "from acdc.TLACDCInterpNode import TLACDCInterpNode\n",
    "from acdc.TLACDCExperiment import TLACDCExperiment\n",
    "\n",
    "from acdc.acdc_utils import (\n",
    "    kl_divergence,\n",
    ")\n",
    "from acdc.ioi.utils import (\n",
    "    get_all_ioi_things,\n",
    "    get_gpt2_small,\n",
    ")\n",
    "from acdc.induction.utils import (\n",
    "    get_all_induction_things,\n",
    "    get_validation_data,\n",
    "    get_good_induction_candidates,\n",
    "    get_mask_repeat_candidates,\n",
    ")\n",
    "from acdc.greaterthan.utils import get_all_greaterthan_things\n",
    "from acdc.text_entailment.utils import get_all_text_entailment_things\n",
    "from acdc.acdc_graphics import (\n",
    "    build_colorscheme,\n",
    "    show,\n",
    ")\n",
    "import argparse\n",
    "\n",
    "torch.autograd.set_grad_enabled(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdd30a0a",
   "metadata": {
    "id": "cdd30a0a"
   },
   "source": [
    "<h2>ACDC Experiment Setup</h2>\n",
    "<p>We use a `parser to set all the options for the ACDC experiment.\n",
    "This is still usable in notebooks! We can pass a string to the parser, see below.\n",
    "We'll reproduce </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "572cf3e2",
   "metadata": {
    "id": "572cf3e2"
   },
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser(description=\"Used to launch ACDC runs. Only task and threshold are required\")\n",
    "\n",
    "task_choices = ['ioi', 'docstring', 'induction', 'tracr-reverse', 'tracr-proportion', 'greaterthan', 'text-entailment']\n",
    "parser.add_argument('--task', type=str, required=True, choices=task_choices, help=f'Choose a task from the available options: {task_choices}')\n",
    "parser.add_argument('--threshold', type=float, required=True, help='Value for THRESHOLD')\n",
    "parser.add_argument('--first-cache-cpu', type=str, required=False, default=\"True\", help='Value for FIRST_CACHE_CPU (the old name for the `online_cache`)')\n",
    "parser.add_argument('--second-cache-cpu', type=str, required=False, default=\"True\", help='Value for SECOND_CACHE_CPU (the old name for the `corrupted_cache`)')\n",
    "parser.add_argument('--zero-ablation', action='store_true', help='Use zero ablation')\n",
    "parser.add_argument('--using-wandb', action='store_true', help='Use wandb')\n",
    "parser.add_argument('--wandb-entity-name', type=str, required=False, default=\"default\", help='Value for WANDB_ENTITY_NAME')\n",
    "parser.add_argument('--wandb-group-name', type=str, required=False, default=\"default\", help='Value for WANDB_GROUP_NAME')\n",
    "parser.add_argument('--wandb-project-name', type=str, required=False, default=\"acdc\", help='Value for WANDB_PROJECT_NAME')\n",
    "parser.add_argument('--wandb-run-name', type=str, required=False, default=None, help='Value for WANDB_RUN_NAME')\n",
    "parser.add_argument(\"--wandb-dir\", type=str, default=\"/tmp/wandb\")\n",
    "parser.add_argument(\"--wandb-mode\", type=str, default=\"online\")\n",
    "parser.add_argument('--indices-mode', type=str, default=\"normal\")\n",
    "parser.add_argument('--names-mode', type=str, default=\"normal\")\n",
    "parser.add_argument('--device', type=str, default=\"cuda\")\n",
    "parser.add_argument('--reset-network', type=int, default=0, help=\"Whether to reset the network we're operating on before running interp on it\")\n",
    "parser.add_argument('--metric', type=str, default=\"kl_div\", help=\"Which metric to use for the experiment\")\n",
    "parser.add_argument('--torch-num-threads', type=int, default=0, help=\"How many threads to use for torch (0=all)\")\n",
    "parser.add_argument('--seed', type=int, default=1234)\n",
    "parser.add_argument(\"--max-num-epochs\",type=int, default=100_000)\n",
    "parser.add_argument('--single-step', action='store_true', help='Use single step, mostly for testing')\n",
    "parser.add_argument(\"--abs-value-threshold\", action='store_true', help='Use the absolute value of the result to check threshold')\n",
    "\n",
    "if ipython is not None:\n",
    "    # We are in a notebook\n",
    "    # you can put the command you would like to run as the ... in r\"\"\"...\"\"\"\n",
    "    args = parser.parse_args(\n",
    "        [line.strip() for line in rf\"\"\"--task=text-entailment\\\n",
    "--threshold=0.000575\\\n",
    "--indices-mode=reverse\\\n",
    "--first-cache-cpu=False\\\n",
    "--second-cache-cpu=False\\\n",
    "--max-num-epochs=100000\\\n",
    "--device=cuda\\\n",
    "--using-wandb\\\n",
    "--wandb-run-name=bert_{MODEL_NAME.split(\"_\")[1]}_nexamples-{NEXAMPLES}\"\"\".split(\"\\\\\\n\")]\n",
    "    )\n",
    "else:\n",
    "    # read from command line\n",
    "    args = parser.parse_args()\n",
    "\n",
    "# Process args\n",
    "\n",
    "if args.torch_num_threads > 0:\n",
    "    torch.set_num_threads(args.torch_num_threads)\n",
    "torch.manual_seed(args.seed)\n",
    "\n",
    "TASK = args.task\n",
    "if args.first_cache_cpu is None: # manage default\n",
    "    ONLINE_CACHE_CPU = True\n",
    "elif args.first_cache_cpu.lower() == \"false\":\n",
    "    ONLINE_CACHE_CPU = False\n",
    "elif args.first_cache_cpu.lower() == \"true\":\n",
    "    ONLINE_CACHE_CPU = True\n",
    "else:\n",
    "    raise ValueError(f\"first_cache_cpu must be either True or False, got {args.first_cache_cpu}\")\n",
    "if args.second_cache_cpu is None:\n",
    "    CORRUPTED_CACHE_CPU = True\n",
    "elif args.second_cache_cpu.lower() == \"false\":\n",
    "    CORRUPTED_CACHE_CPU = False\n",
    "elif args.second_cache_cpu.lower() == \"true\":\n",
    "    CORRUPTED_CACHE_CPU = True\n",
    "else:\n",
    "    raise ValueError(f\"second_cache_cpu must be either True or False, got {args.second_cache_cpu}\")\n",
    "THRESHOLD = args.threshold  # only used if >= 0.0\n",
    "ZERO_ABLATION = True if args.zero_ablation else False\n",
    "USING_WANDB = True if args.using_wandb else False\n",
    "WANDB_ENTITY_NAME = args.wandb_entity_name\n",
    "WANDB_PROJECT_NAME = args.wandb_project_name\n",
    "WANDB_RUN_NAME = args.wandb_run_name\n",
    "WANDB_GROUP_NAME = args.wandb_group_name\n",
    "INDICES_MODE = args.indices_mode\n",
    "NAMES_MODE = args.names_mode\n",
    "DEVICE = args.device\n",
    "RESET_NETWORK = args.reset_network\n",
    "SINGLE_STEP = True if args.single_step else False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c833835c",
   "metadata": {
    "id": "c833835c"
   },
   "source": [
    "<h2>Setup Task</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "89e98237",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 295,
     "referenced_widgets": [
      "95886397324b4670bd62994f8cba7561",
      "01b21ab6851a498189fc5112bdde0d84",
      "71127168c8b54f7da6fe9a5ff18af04e",
      "1c8c04d2d5af4f3ea357658d917a0f53",
      "aa992dbd1b804405acdbddb0184d35f4",
      "b82d99f2b6274234961728058fe21b70",
      "58c56bdd44d34e919fbc8912d56e9826",
      "d7fe10bc29234a2e8fbe3e33a330639d",
      "783faf6175604e53b02327d0acb582b9",
      "4f847958e54d432696ef90260fb69efb",
      "9fc3fcdce1a04843ad2d0c48f90e354c"
     ]
    },
    "id": "89e98237",
    "outputId": "6e3ce470-268f-44d7-b9ef-f9b542cf78a4",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Support for BERT in TransformerLens is currently experimental, until such a time when it has feature parity with HookedTransformer and has been tested on real research tasks. Until then, backward compatibility is not guaranteed. Please see the docs for information on the limitations of the current implementation.\n",
      "If using BERT for interpretability research, keep in mind that BERT has some significant architectural differences to GPT. For example, LayerNorms are applied *after* the attention and MLP components, meaning that the last LayerNorm in a block cannot be folded.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moving model to device:  cuda\n",
      "Loaded pretrained model andres-vs/bert-base-uncased-finetuned_Att-Noneg-depth0 into HookedTransformer\n",
      "Moving model to device:  cuda\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'HookedEncoder' object has no attribute 'set_use_attn_result'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 49\u001b[0m\n\u001b[1;32m     47\u001b[0m     num_examples \u001b[38;5;241m=\u001b[39m NEXAMPLES\n\u001b[1;32m     48\u001b[0m     model_name \u001b[38;5;241m=\u001b[39m MODEL_NAME\n\u001b[0;32m---> 49\u001b[0m     things \u001b[38;5;241m=\u001b[39m \u001b[43mget_all_text_entailment_things\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     50\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_examples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_examples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetric_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmetric\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mDEVICE\u001b[49m\n\u001b[1;32m     51\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnknown task \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mTASK\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/mnt/c/Users/andre/Documents/School/Hoger/Masterproef/Code/Automatic-Circuit-Discovery/acdc/text_entailment/utils.py:62\u001b[0m, in \u001b[0;36mget_all_text_entailment_things\u001b[0;34m(model_name, num_examples, device, metric_name, kl_return_one_element)\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_all_text_entailment_things\u001b[39m(model_name, num_examples, device, metric_name, kl_return_one_element\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m---> 62\u001b[0m     tl_model\u001b[38;5;241m=\u001b[39m\u001b[43mget_finetuned_bert_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     64\u001b[0m     login(token\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhf_BVEOnTjkPCAKIwvwprnlbkdwVGMTBxIjGz\u001b[39m\u001b[38;5;124m\"\u001b[39m, add_to_git_credential\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     65\u001b[0m     dataset_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mandres-vs/ruletaker-Att-Noneg-depth0\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m/mnt/c/Users/andre/Documents/School/Hoger/Masterproef/Code/Automatic-Circuit-Discovery/acdc/text_entailment/utils.py:29\u001b[0m, in \u001b[0;36mget_finetuned_bert_model\u001b[0;34m(model_name, device)\u001b[0m\n\u001b[1;32m     27\u001b[0m tl_model \u001b[38;5;241m=\u001b[39m HookedEncoder\u001b[38;5;241m.\u001b[39mfrom_pretrained(model_name, tokenizer\u001b[38;5;241m=\u001b[39mtokenizer) \u001b[38;5;66;03m#, fold_ln=False)\u001b[39;00m\n\u001b[1;32m     28\u001b[0m tl_model \u001b[38;5;241m=\u001b[39m tl_model\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m---> 29\u001b[0m \u001b[43mtl_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset_use_attn_result\u001b[49m(\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     30\u001b[0m tl_model\u001b[38;5;241m.\u001b[39mset_use_split_qkv_input(\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28mprint\u001b[39m(tl_model\u001b[38;5;241m.\u001b[39mcfg\u001b[38;5;241m.\u001b[39mto_dict())\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1688\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1686\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m modules:\n\u001b[1;32m   1687\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m modules[name]\n\u001b[0;32m-> 1688\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m object has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'HookedEncoder' object has no attribute 'set_use_attn_result'"
     ]
    }
   ],
   "source": [
    "\n",
    "second_metric = None  # some tasks only have one metric\n",
    "use_pos_embed = TASK.startswith(\"tracr\")\n",
    "\n",
    "if TASK == \"ioi\":\n",
    "    num_examples = 100\n",
    "    things = get_all_ioi_things(\n",
    "        num_examples=num_examples, device=DEVICE, metric_name=args.metric\n",
    "    )\n",
    "elif TASK == \"tracr-reverse\":\n",
    "    num_examples = 6\n",
    "    things = get_all_tracr_things(\n",
    "        task=\"reverse\",\n",
    "        metric_name=args.metric,\n",
    "        num_examples=num_examples,\n",
    "        device=DEVICE,\n",
    "    )\n",
    "elif TASK == \"tracr-proportion\":\n",
    "    num_examples = 50\n",
    "    things = get_all_tracr_things(\n",
    "        task=\"proportion\",\n",
    "        metric_name=args.metric,\n",
    "        num_examples=num_examples,\n",
    "        device=DEVICE,\n",
    "    )\n",
    "elif TASK == \"induction\":\n",
    "    num_examples = 10\n",
    "    seq_len = 300\n",
    "    things = get_all_induction_things(\n",
    "        num_examples=num_examples, seq_len=seq_len, device=DEVICE, metric=args.metric\n",
    "    )\n",
    "elif TASK == \"docstring\":\n",
    "    num_examples = 50\n",
    "    seq_len = 41\n",
    "    things = get_all_docstring_things(\n",
    "        num_examples=num_examples,\n",
    "        seq_len=seq_len,\n",
    "        device=DEVICE,\n",
    "        metric_name=args.metric,\n",
    "        correct_incorrect_wandb=True,\n",
    "    )\n",
    "elif TASK == \"greaterthan\":\n",
    "    num_examples = 100\n",
    "    things = get_all_greaterthan_things(\n",
    "        num_examples=num_examples, metric_name=args.metric, device=DEVICE\n",
    "    )\n",
    "elif TASK == \"text-entailment\":\n",
    "    num_examples = NEXAMPLES\n",
    "    model_name = MODEL_NAME\n",
    "    things = get_all_text_entailment_things(\n",
    "        model_name=model_name, num_examples=num_examples, metric_name=args.metric, device=DEVICE\n",
    "    )\n",
    "else:\n",
    "    raise ValueError(f\"Unknown task {TASK}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "rG-vmGnsAiM4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rG-vmGnsAiM4",
    "outputId": "43bcba8d-d118-4c93-a852-20026884050f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "JnbYGE5vAmIp",
   "metadata": {
    "id": "JnbYGE5vAmIp"
   },
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "891f8969",
   "metadata": {
    "id": "891f8969"
   },
   "source": [
    "<p> Let's define the four most important objects for ACDC experiments:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b5053907",
   "metadata": {
    "id": "b5053907"
   },
   "outputs": [],
   "source": [
    "\n",
    "validation_metric = things.validation_metric # metric we use (e.g KL divergence)\n",
    "toks_int_values = things.validation_data # clean data x_i\n",
    "toks_int_values_other = things.validation_patch_data # corrupted data x_i'\n",
    "tl_model = things.tl_model # transformerlens model\n",
    "\n",
    "if RESET_NETWORK:\n",
    "    reset_network(TASK, DEVICE, tl_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "e5BCrnU-iDwq",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e5BCrnU-iDwq",
    "outputId": "d1000126-b24a-4418-b6cf-629a129cfe28"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total size of toks_int_values in bytes: 10000\n",
      "Total size of toks_int_values_other in bytes: 10000\n",
      "torch.Size([10, 125]) torch.Size([10, 125])\n"
     ]
    }
   ],
   "source": [
    "print(\"Total size of toks_int_values in bytes:\", toks_int_values.element_size() * toks_int_values.numel())\n",
    "print(\"Total size of toks_int_values_other in bytes:\", toks_int_values_other.element_size() * toks_int_values_other.numel())\n",
    "print(toks_int_values.size(), toks_int_values_other.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "XqE-va6fQp-o",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 142
    },
    "id": "XqE-va6fQp-o",
    "outputId": "5ae344a8-fc07-464d-e8b8-7dc817d06a2a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "wandb version 0.16.6 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.11"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/content/wandb/run-20240427_111526-mlanh0ed</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/andresvanschel/acdc/runs/mlanh0ed' target=\"_blank\">test</a></strong> to <a href='https://wandb.ai/andresvanschel/acdc' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/andresvanschel/acdc' target=\"_blank\">https://wandb.ai/andresvanschel/acdc</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/andresvanschel/acdc/runs/mlanh0ed' target=\"_blank\">https://wandb.ai/andresvanschel/acdc/runs/mlanh0ed</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/andresvanschel/acdc/runs/mlanh0ed?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x7edd987bb2e0>"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.init(project='acdc', name=\"test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43f9cd73",
   "metadata": {
    "id": "43f9cd73"
   },
   "source": [
    "<h2>Setup ACDC Experiment</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "2925fee6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "44e291f5c9474bb7ba9e093039ebe683",
      "4ece0a17b74e48cda581bc50db67cae1",
      "e5f088bc64e442bcb1a952ccfd7d5e6d",
      "24347ef554574e9fa8ef4f59ebfd9601",
      "ab22f4e3d96f409ba3d2f556c8e98c6a",
      "801fd09a08044efeacd71458ef758a9f",
      "3f9414296baf44b0bf601c16a3e1bca8",
      "836d6affb51f436fa5bf94d0ae3c1129"
     ]
    },
    "id": "2925fee6",
    "outputId": "a9ce490c-4e18-4e19-c3e8-29743cf6da25"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:cache_all is deprecated and will eventually be removed, use add_caching_hooks or run_with_cache\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['blocks.11.hook_resid_post', 'blocks.11.hook_mlp_out', 'blocks.11.hook_mlp_in', 'blocks.11.attn.hook_result', 'blocks.11.attn.hook_q', 'blocks.11.hook_q_input', 'blocks.11.attn.hook_k', 'blocks.11.hook_k_input', 'blocks.11.attn.hook_v', 'blocks.11.hook_v_input', 'blocks.10.hook_mlp_out', 'blocks.10.hook_mlp_in', 'blocks.10.attn.hook_result', 'blocks.10.attn.hook_q', 'blocks.10.hook_q_input', 'blocks.10.attn.hook_k', 'blocks.10.hook_k_input', 'blocks.10.attn.hook_v', 'blocks.10.hook_v_input', 'blocks.9.hook_mlp_out', 'blocks.9.hook_mlp_in', 'blocks.9.attn.hook_result', 'blocks.9.attn.hook_q', 'blocks.9.hook_q_input', 'blocks.9.attn.hook_k', 'blocks.9.hook_k_input', 'blocks.9.attn.hook_v', 'blocks.9.hook_v_input', 'blocks.8.hook_mlp_out', 'blocks.8.hook_mlp_in', 'blocks.8.attn.hook_result', 'blocks.8.attn.hook_q', 'blocks.8.hook_q_input', 'blocks.8.attn.hook_k', 'blocks.8.hook_k_input', 'blocks.8.attn.hook_v', 'blocks.8.hook_v_input', 'blocks.7.hook_mlp_out', 'blocks.7.hook_mlp_in', 'blocks.7.attn.hook_result', 'blocks.7.attn.hook_q', 'blocks.7.hook_q_input', 'blocks.7.attn.hook_k', 'blocks.7.hook_k_input', 'blocks.7.attn.hook_v', 'blocks.7.hook_v_input', 'blocks.6.hook_mlp_out', 'blocks.6.hook_mlp_in', 'blocks.6.attn.hook_result', 'blocks.6.attn.hook_q', 'blocks.6.hook_q_input', 'blocks.6.attn.hook_k', 'blocks.6.hook_k_input', 'blocks.6.attn.hook_v', 'blocks.6.hook_v_input', 'blocks.5.hook_mlp_out', 'blocks.5.hook_mlp_in', 'blocks.5.attn.hook_result', 'blocks.5.attn.hook_q', 'blocks.5.hook_q_input', 'blocks.5.attn.hook_k', 'blocks.5.hook_k_input', 'blocks.5.attn.hook_v', 'blocks.5.hook_v_input', 'blocks.4.hook_mlp_out', 'blocks.4.hook_mlp_in', 'blocks.4.attn.hook_result', 'blocks.4.attn.hook_q', 'blocks.4.hook_q_input', 'blocks.4.attn.hook_k', 'blocks.4.hook_k_input', 'blocks.4.attn.hook_v', 'blocks.4.hook_v_input', 'blocks.3.hook_mlp_out', 'blocks.3.hook_mlp_in', 'blocks.3.attn.hook_result', 'blocks.3.attn.hook_q', 'blocks.3.hook_q_input', 'blocks.3.attn.hook_k', 'blocks.3.hook_k_input', 'blocks.3.attn.hook_v', 'blocks.3.hook_v_input', 'blocks.2.hook_mlp_out', 'blocks.2.hook_mlp_in', 'blocks.2.attn.hook_result', 'blocks.2.attn.hook_q', 'blocks.2.hook_q_input', 'blocks.2.attn.hook_k', 'blocks.2.hook_k_input', 'blocks.2.attn.hook_v', 'blocks.2.hook_v_input', 'blocks.1.hook_mlp_out', 'blocks.1.hook_mlp_in', 'blocks.1.attn.hook_result', 'blocks.1.attn.hook_q', 'blocks.1.hook_q_input', 'blocks.1.attn.hook_k', 'blocks.1.hook_k_input', 'blocks.1.attn.hook_v', 'blocks.1.hook_v_input', 'blocks.0.hook_mlp_out', 'blocks.0.hook_mlp_in', 'blocks.0.attn.hook_result', 'blocks.0.attn.hook_q', 'blocks.0.hook_q_input', 'blocks.0.attn.hook_k', 'blocks.0.hook_k_input', 'blocks.0.attn.hook_v', 'blocks.0.hook_v_input', 'blocks.0.hook_resid_pre'])\n",
      "mlm_head.ln.hook_normalized\n",
      "mlm_head.ln.hook_scale\n",
      "blocks.11.hook_normalized_resid_post\n",
      "blocks.11.ln2.hook_normalized\n",
      "blocks.11.ln2.hook_scale\n",
      "blocks.11.hook_resid_post\n",
      "blocks.11.hook_mlp_out\n",
      "blocks.11.mlp.hook_post\n",
      "blocks.11.mlp.hook_pre\n",
      "blocks.11.ln1.hook_normalized\n",
      "blocks.11.ln1.hook_scale\n",
      "blocks.11.hook_mlp_in\n",
      "blocks.11.hook_resid_mid\n",
      "blocks.11.hook_attn_out\n",
      "blocks.11.attn.hook_result\n",
      "blocks.11.attn.hook_z\n",
      "blocks.11.attn.hook_pattern\n",
      "blocks.11.attn.hook_attn_scores\n",
      "blocks.11.attn.hook_v\n",
      "blocks.11.attn.hook_k\n",
      "blocks.11.attn.hook_q\n",
      "blocks.11.hook_v_input\n",
      "blocks.11.hook_k_input\n",
      "blocks.11.hook_q_input\n",
      "blocks.11.hook_resid_pre\n",
      "blocks.10.hook_normalized_resid_post\n",
      "blocks.10.ln2.hook_normalized\n",
      "blocks.10.ln2.hook_scale\n",
      "blocks.10.hook_resid_post\n",
      "blocks.10.hook_mlp_out\n",
      "blocks.10.mlp.hook_post\n",
      "blocks.10.mlp.hook_pre\n",
      "blocks.10.ln1.hook_normalized\n",
      "blocks.10.ln1.hook_scale\n",
      "blocks.10.hook_mlp_in\n",
      "blocks.10.hook_resid_mid\n",
      "blocks.10.hook_attn_out\n",
      "blocks.10.attn.hook_result\n",
      "blocks.10.attn.hook_z\n",
      "blocks.10.attn.hook_pattern\n",
      "blocks.10.attn.hook_attn_scores\n",
      "blocks.10.attn.hook_v\n",
      "blocks.10.attn.hook_k\n",
      "blocks.10.attn.hook_q\n",
      "blocks.10.hook_v_input\n",
      "blocks.10.hook_k_input\n",
      "blocks.10.hook_q_input\n",
      "blocks.10.hook_resid_pre\n",
      "blocks.9.hook_normalized_resid_post\n",
      "blocks.9.ln2.hook_normalized\n",
      "blocks.9.ln2.hook_scale\n",
      "blocks.9.hook_resid_post\n",
      "blocks.9.hook_mlp_out\n",
      "blocks.9.mlp.hook_post\n",
      "blocks.9.mlp.hook_pre\n",
      "blocks.9.ln1.hook_normalized\n",
      "blocks.9.ln1.hook_scale\n",
      "blocks.9.hook_mlp_in\n",
      "blocks.9.hook_resid_mid\n",
      "blocks.9.hook_attn_out\n",
      "blocks.9.attn.hook_result\n",
      "blocks.9.attn.hook_z\n",
      "blocks.9.attn.hook_pattern\n",
      "blocks.9.attn.hook_attn_scores\n",
      "blocks.9.attn.hook_v\n",
      "blocks.9.attn.hook_k\n",
      "blocks.9.attn.hook_q\n",
      "blocks.9.hook_v_input\n",
      "blocks.9.hook_k_input\n",
      "blocks.9.hook_q_input\n",
      "blocks.9.hook_resid_pre\n",
      "blocks.8.hook_normalized_resid_post\n",
      "blocks.8.ln2.hook_normalized\n",
      "blocks.8.ln2.hook_scale\n",
      "blocks.8.hook_resid_post\n",
      "blocks.8.hook_mlp_out\n",
      "blocks.8.mlp.hook_post\n",
      "blocks.8.mlp.hook_pre\n",
      "blocks.8.ln1.hook_normalized\n",
      "blocks.8.ln1.hook_scale\n",
      "blocks.8.hook_mlp_in\n",
      "blocks.8.hook_resid_mid\n",
      "blocks.8.hook_attn_out\n",
      "blocks.8.attn.hook_result\n",
      "blocks.8.attn.hook_z\n",
      "blocks.8.attn.hook_pattern\n",
      "blocks.8.attn.hook_attn_scores\n",
      "blocks.8.attn.hook_v\n",
      "blocks.8.attn.hook_k\n",
      "blocks.8.attn.hook_q\n",
      "blocks.8.hook_v_input\n",
      "blocks.8.hook_k_input\n",
      "blocks.8.hook_q_input\n",
      "blocks.8.hook_resid_pre\n",
      "blocks.7.hook_normalized_resid_post\n",
      "blocks.7.ln2.hook_normalized\n",
      "blocks.7.ln2.hook_scale\n",
      "blocks.7.hook_resid_post\n",
      "blocks.7.hook_mlp_out\n",
      "blocks.7.mlp.hook_post\n",
      "blocks.7.mlp.hook_pre\n",
      "blocks.7.ln1.hook_normalized\n",
      "blocks.7.ln1.hook_scale\n",
      "blocks.7.hook_mlp_in\n",
      "blocks.7.hook_resid_mid\n",
      "blocks.7.hook_attn_out\n",
      "blocks.7.attn.hook_result\n",
      "blocks.7.attn.hook_z\n",
      "blocks.7.attn.hook_pattern\n",
      "blocks.7.attn.hook_attn_scores\n",
      "blocks.7.attn.hook_v\n",
      "blocks.7.attn.hook_k\n",
      "blocks.7.attn.hook_q\n",
      "blocks.7.hook_v_input\n",
      "blocks.7.hook_k_input\n",
      "blocks.7.hook_q_input\n",
      "blocks.7.hook_resid_pre\n",
      "blocks.6.hook_normalized_resid_post\n",
      "blocks.6.ln2.hook_normalized\n",
      "blocks.6.ln2.hook_scale\n",
      "blocks.6.hook_resid_post\n",
      "blocks.6.hook_mlp_out\n",
      "blocks.6.mlp.hook_post\n",
      "blocks.6.mlp.hook_pre\n",
      "blocks.6.ln1.hook_normalized\n",
      "blocks.6.ln1.hook_scale\n",
      "blocks.6.hook_mlp_in\n",
      "blocks.6.hook_resid_mid\n",
      "blocks.6.hook_attn_out\n",
      "blocks.6.attn.hook_result\n",
      "blocks.6.attn.hook_z\n",
      "blocks.6.attn.hook_pattern\n",
      "blocks.6.attn.hook_attn_scores\n",
      "blocks.6.attn.hook_v\n",
      "blocks.6.attn.hook_k\n",
      "blocks.6.attn.hook_q\n",
      "blocks.6.hook_v_input\n",
      "blocks.6.hook_k_input\n",
      "blocks.6.hook_q_input\n",
      "blocks.6.hook_resid_pre\n",
      "blocks.5.hook_normalized_resid_post\n",
      "blocks.5.ln2.hook_normalized\n",
      "blocks.5.ln2.hook_scale\n",
      "blocks.5.hook_resid_post\n",
      "blocks.5.hook_mlp_out\n",
      "blocks.5.mlp.hook_post\n",
      "blocks.5.mlp.hook_pre\n",
      "blocks.5.ln1.hook_normalized\n",
      "blocks.5.ln1.hook_scale\n",
      "blocks.5.hook_mlp_in\n",
      "blocks.5.hook_resid_mid\n",
      "blocks.5.hook_attn_out\n",
      "blocks.5.attn.hook_result\n",
      "blocks.5.attn.hook_z\n",
      "blocks.5.attn.hook_pattern\n",
      "blocks.5.attn.hook_attn_scores\n",
      "blocks.5.attn.hook_v\n",
      "blocks.5.attn.hook_k\n",
      "blocks.5.attn.hook_q\n",
      "blocks.5.hook_v_input\n",
      "blocks.5.hook_k_input\n",
      "blocks.5.hook_q_input\n",
      "blocks.5.hook_resid_pre\n",
      "blocks.4.hook_normalized_resid_post\n",
      "blocks.4.ln2.hook_normalized\n",
      "blocks.4.ln2.hook_scale\n",
      "blocks.4.hook_resid_post\n",
      "blocks.4.hook_mlp_out\n",
      "blocks.4.mlp.hook_post\n",
      "blocks.4.mlp.hook_pre\n",
      "blocks.4.ln1.hook_normalized\n",
      "blocks.4.ln1.hook_scale\n",
      "blocks.4.hook_mlp_in\n",
      "blocks.4.hook_resid_mid\n",
      "blocks.4.hook_attn_out\n",
      "blocks.4.attn.hook_result\n",
      "blocks.4.attn.hook_z\n",
      "blocks.4.attn.hook_pattern\n",
      "blocks.4.attn.hook_attn_scores\n",
      "blocks.4.attn.hook_v\n",
      "blocks.4.attn.hook_k\n",
      "blocks.4.attn.hook_q\n",
      "blocks.4.hook_v_input\n",
      "blocks.4.hook_k_input\n",
      "blocks.4.hook_q_input\n",
      "blocks.4.hook_resid_pre\n",
      "blocks.3.hook_normalized_resid_post\n",
      "blocks.3.ln2.hook_normalized\n",
      "blocks.3.ln2.hook_scale\n",
      "blocks.3.hook_resid_post\n",
      "blocks.3.hook_mlp_out\n",
      "blocks.3.mlp.hook_post\n",
      "blocks.3.mlp.hook_pre\n",
      "blocks.3.ln1.hook_normalized\n",
      "blocks.3.ln1.hook_scale\n",
      "blocks.3.hook_mlp_in\n",
      "blocks.3.hook_resid_mid\n",
      "blocks.3.hook_attn_out\n",
      "blocks.3.attn.hook_result\n",
      "blocks.3.attn.hook_z\n",
      "blocks.3.attn.hook_pattern\n",
      "blocks.3.attn.hook_attn_scores\n",
      "blocks.3.attn.hook_v\n",
      "blocks.3.attn.hook_k\n",
      "blocks.3.attn.hook_q\n",
      "blocks.3.hook_v_input\n",
      "blocks.3.hook_k_input\n",
      "blocks.3.hook_q_input\n",
      "blocks.3.hook_resid_pre\n",
      "blocks.2.hook_normalized_resid_post\n",
      "blocks.2.ln2.hook_normalized\n",
      "blocks.2.ln2.hook_scale\n",
      "blocks.2.hook_resid_post\n",
      "blocks.2.hook_mlp_out\n",
      "blocks.2.mlp.hook_post\n",
      "blocks.2.mlp.hook_pre\n",
      "blocks.2.ln1.hook_normalized\n",
      "blocks.2.ln1.hook_scale\n",
      "blocks.2.hook_mlp_in\n",
      "blocks.2.hook_resid_mid\n",
      "blocks.2.hook_attn_out\n",
      "blocks.2.attn.hook_result\n",
      "blocks.2.attn.hook_z\n",
      "blocks.2.attn.hook_pattern\n",
      "blocks.2.attn.hook_attn_scores\n",
      "blocks.2.attn.hook_v\n",
      "blocks.2.attn.hook_k\n",
      "blocks.2.attn.hook_q\n",
      "blocks.2.hook_v_input\n",
      "blocks.2.hook_k_input\n",
      "blocks.2.hook_q_input\n",
      "blocks.2.hook_resid_pre\n",
      "blocks.1.hook_normalized_resid_post\n",
      "blocks.1.ln2.hook_normalized\n",
      "blocks.1.ln2.hook_scale\n",
      "blocks.1.hook_resid_post\n",
      "blocks.1.hook_mlp_out\n",
      "blocks.1.mlp.hook_post\n",
      "blocks.1.mlp.hook_pre\n",
      "blocks.1.ln1.hook_normalized\n",
      "blocks.1.ln1.hook_scale\n",
      "blocks.1.hook_mlp_in\n",
      "blocks.1.hook_resid_mid\n",
      "blocks.1.hook_attn_out\n",
      "blocks.1.attn.hook_result\n",
      "blocks.1.attn.hook_z\n",
      "blocks.1.attn.hook_pattern\n",
      "blocks.1.attn.hook_attn_scores\n",
      "blocks.1.attn.hook_v\n",
      "blocks.1.attn.hook_k\n",
      "blocks.1.attn.hook_q\n",
      "blocks.1.hook_v_input\n",
      "blocks.1.hook_k_input\n",
      "blocks.1.hook_q_input\n",
      "blocks.1.hook_resid_pre\n",
      "blocks.0.hook_normalized_resid_post\n",
      "blocks.0.ln2.hook_normalized\n",
      "blocks.0.ln2.hook_scale\n",
      "blocks.0.hook_resid_post\n",
      "blocks.0.hook_mlp_out\n",
      "blocks.0.mlp.hook_post\n",
      "blocks.0.mlp.hook_pre\n",
      "blocks.0.ln1.hook_normalized\n",
      "blocks.0.ln1.hook_scale\n",
      "blocks.0.hook_mlp_in\n",
      "blocks.0.hook_resid_mid\n",
      "blocks.0.hook_attn_out\n",
      "blocks.0.attn.hook_result\n",
      "blocks.0.attn.hook_z\n",
      "blocks.0.attn.hook_pattern\n",
      "blocks.0.attn.hook_attn_scores\n",
      "blocks.0.attn.hook_v\n",
      "blocks.0.attn.hook_k\n",
      "blocks.0.attn.hook_q\n",
      "blocks.0.hook_v_input\n",
      "blocks.0.hook_k_input\n",
      "blocks.0.hook_q_input\n",
      "blocks.0.hook_resid_pre\n",
      "hook_full_embed\n",
      "embed.ln.hook_normalized\n",
      "embed.ln.hook_scale\n",
      "embed.hook_token_type_embed\n",
      "embed.hook_pos_embed\n",
      "embed.hook_embed\n",
      "self.current_node=TLACDCInterpNode(blocks.11.hook_resid_post, [:])\n",
      "Mem before corruption 2058653184\n",
      "Press Enter to continue.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:cache_all is deprecated and will eventually be removed, use add_caching_hooks or run_with_cache\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding sender hooks...\n",
      "Done corrupting things\n",
      "Mem after corruption 5347546624\n",
      "Press Enter to continue.\n",
      "Adding sender hooks...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:ptlop1ul) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44e291f5c9474bb7ba9e093039ebe683",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.094 MB of 0.094 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>cur_metric</td><td></td></tr><tr><td>experiment.cur_metric</td><td></td></tr><tr><td>num_edges</td><td></td></tr><tr><td>num_edges_total</td><td></td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>cur_metric</td><td>0.0</td></tr><tr><td>experiment.cur_metric</td><td>0.0</td></tr><tr><td>num_edges</td><td>32779</td></tr><tr><td>num_edges_total</td><td>32776</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">Sat_Apr_27_19_23_27_2024_0.0575</strong> at: <a href='https://wandb.ai/andresvanschel/acdc/runs/ptlop1ul' target=\"_blank\">https://wandb.ai/andresvanschel/acdc/runs/ptlop1ul</a><br/>Synced 5 W&B file(s), 7 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>/tmp/wandb/wandb/run-20240427_192346-ptlop1ul/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:ptlop1ul). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.6 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.11"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/tmp/wandb/wandb/run-20240427_192701-fz3uarwd</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/andresvanschel/acdc/runs/fz3uarwd' target=\"_blank\">Sat_Apr_27_19_26_52_2024_0.000575</a></strong> to <a href='https://wandb.ai/andresvanschel/acdc' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/andresvanschel/acdc' target=\"_blank\">https://wandb.ai/andresvanschel/acdc</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/andresvanschel/acdc/runs/fz3uarwd' target=\"_blank\">https://wandb.ai/andresvanschel/acdc/runs/fz3uarwd</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No edge 32923\n",
      "Mem after update metric 7800047104\n",
      "Press Enter to continue.\n"
     ]
    }
   ],
   "source": [
    "# Make notes for potential wandb run\n",
    "try:\n",
    "    with open(__file__, \"r\") as f:\n",
    "        notes = f.read()\n",
    "except:\n",
    "    notes = \"No notes generated, expected when running in an .ipynb file\"\n",
    "\n",
    "tl_model.reset_hooks()\n",
    "\n",
    "# Save some mem\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "# Setup wandb if needed\n",
    "if WANDB_RUN_NAME is None or IPython.get_ipython() is not None:\n",
    "    WANDB_RUN_NAME = f\"{ct()}{'_randomindices' if INDICES_MODE=='random' else ''}_{THRESHOLD}{'_zero' if ZERO_ABLATION else ''}\"\n",
    "else:\n",
    "    assert WANDB_RUN_NAME is not None, \"I want named runs, always\"\n",
    "\n",
    "tl_model.reset_hooks()\n",
    "exp = TLACDCExperiment(\n",
    "    model=tl_model,\n",
    "    threshold=THRESHOLD,\n",
    "    using_wandb=USING_WANDB,\n",
    "    wandb_entity_name=WANDB_ENTITY_NAME,\n",
    "    wandb_project_name=WANDB_PROJECT_NAME,\n",
    "    wandb_run_name=WANDB_RUN_NAME,\n",
    "    wandb_group_name=WANDB_GROUP_NAME,\n",
    "    wandb_notes=notes,\n",
    "    wandb_dir=args.wandb_dir,\n",
    "    wandb_mode=args.wandb_mode,\n",
    "    wandb_config=args,\n",
    "    zero_ablation=ZERO_ABLATION,\n",
    "    abs_value_threshold=args.abs_value_threshold,\n",
    "    ds=toks_int_values,\n",
    "    ref_ds=toks_int_values_other,\n",
    "    metric=validation_metric,\n",
    "    second_metric=second_metric,\n",
    "    verbose=True,\n",
    "    indices_mode=INDICES_MODE,\n",
    "    names_mode=NAMES_MODE,\n",
    "    corrupted_cache_cpu=CORRUPTED_CACHE_CPU,\n",
    "    hook_verbose=False,\n",
    "    online_cache_cpu=ONLINE_CACHE_CPU,\n",
    "    add_sender_hooks=True,\n",
    "    use_pos_embed=use_pos_embed,\n",
    "    add_receiver_hooks=False,\n",
    "    remove_redundant=False,\n",
    "    show_full_index=use_pos_embed,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69d58f55",
   "metadata": {
    "id": "69d58f55"
   },
   "source": [
    "<h2>Run steps of ACDC: iterate over a NODE in the model's computational graph</h2>\n",
    "<p>WARNING! This will take a few minutes to run, but there should be rolling nice pictures too : )</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "1fce3f65",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "1fce3f65",
    "outputId": "124245d2-7259-405b-efaf-2bf35dedb14e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No edge 32923\n",
      "New metric: 0.0\n",
      "\n",
      "Node: cur_parent=TLACDCInterpNode(blocks.11.hook_mlp_out, [:]) (self.current_node=TLACDCInterpNode(blocks.11.hook_resid_post, [:]))\n",
      "\n",
      "Metric after removing connection to blocks.11.hook_mlp_out [:] is 0.0 (and current metric 0.0)\n",
      "Result is 0.0...so removing connection\n",
      "No edge 32922\n",
      "No edge 32922\n",
      "\n",
      "Node: cur_parent=TLACDCInterpNode(blocks.11.attn.hook_result, [:, :, 0]) (self.current_node=TLACDCInterpNode(blocks.11.hook_resid_post, [:]))\n",
      "\n",
      "Metric after removing connection to blocks.11.attn.hook_result [:, :, 0] is 0.0 (and current metric 0.0)\n",
      "Result is 0.0...so removing connection\n",
      "No edge 32921\n",
      "\n",
      "Node: cur_parent=TLACDCInterpNode(blocks.11.attn.hook_result, [:, :, 1]) (self.current_node=TLACDCInterpNode(blocks.11.hook_resid_post, [:]))\n",
      "\n",
      "Metric after removing connection to blocks.11.attn.hook_result [:, :, 1] is 0.0 (and current metric 0.0)\n",
      "Result is 0.0...so removing connection\n",
      "No edge 32920\n",
      "\n",
      "Node: cur_parent=TLACDCInterpNode(blocks.11.attn.hook_result, [:, :, 2]) (self.current_node=TLACDCInterpNode(blocks.11.hook_resid_post, [:]))\n",
      "\n",
      "Metric after removing connection to blocks.11.attn.hook_result [:, :, 2] is 0.0 (and current metric 0.0)\n",
      "Result is 0.0...so removing connection\n",
      "No edge 32919\n",
      "\n",
      "Node: cur_parent=TLACDCInterpNode(blocks.11.attn.hook_result, [:, :, 3]) (self.current_node=TLACDCInterpNode(blocks.11.hook_resid_post, [:]))\n",
      "\n",
      "Metric after removing connection to blocks.11.attn.hook_result [:, :, 3] is 0.0 (and current metric 0.0)\n",
      "Result is 0.0...so removing connection\n",
      "No edge 32918\n",
      "\n",
      "Node: cur_parent=TLACDCInterpNode(blocks.11.attn.hook_result, [:, :, 4]) (self.current_node=TLACDCInterpNode(blocks.11.hook_resid_post, [:]))\n",
      "\n",
      "Metric after removing connection to blocks.11.attn.hook_result [:, :, 4] is 0.0 (and current metric 0.0)\n",
      "Result is 0.0...so removing connection\n",
      "No edge 32917\n",
      "\n",
      "Node: cur_parent=TLACDCInterpNode(blocks.11.attn.hook_result, [:, :, 5]) (self.current_node=TLACDCInterpNode(blocks.11.hook_resid_post, [:]))\n",
      "\n",
      "Metric after removing connection to blocks.11.attn.hook_result [:, :, 5] is 0.0 (and current metric 0.0)\n",
      "Result is 0.0...so removing connection\n",
      "No edge 32916\n",
      "\n",
      "Node: cur_parent=TLACDCInterpNode(blocks.11.attn.hook_result, [:, :, 6]) (self.current_node=TLACDCInterpNode(blocks.11.hook_resid_post, [:]))\n",
      "\n",
      "Metric after removing connection to blocks.11.attn.hook_result [:, :, 6] is 0.0 (and current metric 0.0)\n",
      "Result is 0.0...so removing connection\n",
      "No edge 32915\n",
      "\n",
      "Node: cur_parent=TLACDCInterpNode(blocks.11.attn.hook_result, [:, :, 7]) (self.current_node=TLACDCInterpNode(blocks.11.hook_resid_post, [:]))\n",
      "\n",
      "Metric after removing connection to blocks.11.attn.hook_result [:, :, 7] is 0.0 (and current metric 0.0)\n",
      "Result is 0.0...so removing connection\n",
      "No edge 32914\n",
      "\n",
      "Node: cur_parent=TLACDCInterpNode(blocks.11.attn.hook_result, [:, :, 8]) (self.current_node=TLACDCInterpNode(blocks.11.hook_resid_post, [:]))\n",
      "\n",
      "Metric after removing connection to blocks.11.attn.hook_result [:, :, 8] is 0.0 (and current metric 0.0)\n",
      "Result is 0.0...so removing connection\n",
      "No edge 32913\n",
      "\n",
      "Node: cur_parent=TLACDCInterpNode(blocks.11.attn.hook_result, [:, :, 9]) (self.current_node=TLACDCInterpNode(blocks.11.hook_resid_post, [:]))\n",
      "\n",
      "Metric after removing connection to blocks.11.attn.hook_result [:, :, 9] is 0.0 (and current metric 0.0)\n",
      "Result is 0.0...so removing connection\n",
      "No edge 32912\n",
      "\n",
      "Node: cur_parent=TLACDCInterpNode(blocks.11.attn.hook_result, [:, :, 10]) (self.current_node=TLACDCInterpNode(blocks.11.hook_resid_post, [:]))\n",
      "\n",
      "Metric after removing connection to blocks.11.attn.hook_result [:, :, 10] is 0.0 (and current metric 0.0)\n",
      "Result is 0.0...so removing connection\n",
      "No edge 32911\n",
      "\n",
      "Node: cur_parent=TLACDCInterpNode(blocks.11.attn.hook_result, [:, :, 11]) (self.current_node=TLACDCInterpNode(blocks.11.hook_resid_post, [:]))\n",
      "\n",
      "Metric after removing connection to blocks.11.attn.hook_result [:, :, 11] is 0.0 (and current metric 0.0)\n",
      "Result is 0.0...so removing connection\n",
      "No edge 32910\n",
      "No edge 32910\n",
      "\n",
      "Node: cur_parent=TLACDCInterpNode(blocks.10.hook_mlp_out, [:]) (self.current_node=TLACDCInterpNode(blocks.11.hook_resid_post, [:]))\n",
      "\n",
      "Metric after removing connection to blocks.10.hook_mlp_out [:] is 0.0 (and current metric 0.0)\n",
      "Result is 0.0...so removing connection\n",
      "No edge 32909\n",
      "No edge 32909\n",
      "\n",
      "Node: cur_parent=TLACDCInterpNode(blocks.10.attn.hook_result, [:, :, 0]) (self.current_node=TLACDCInterpNode(blocks.11.hook_resid_post, [:]))\n",
      "\n",
      "Metric after removing connection to blocks.10.attn.hook_result [:, :, 0] is 0.0 (and current metric 0.0)\n",
      "Result is 0.0...so removing connection\n",
      "No edge 32908\n",
      "\n",
      "Node: cur_parent=TLACDCInterpNode(blocks.10.attn.hook_result, [:, :, 1]) (self.current_node=TLACDCInterpNode(blocks.11.hook_resid_post, [:]))\n",
      "\n",
      "Metric after removing connection to blocks.10.attn.hook_result [:, :, 1] is 0.0 (and current metric 0.0)\n",
      "Result is 0.0...so removing connection\n",
      "No edge 32907\n",
      "\n",
      "Node: cur_parent=TLACDCInterpNode(blocks.10.attn.hook_result, [:, :, 2]) (self.current_node=TLACDCInterpNode(blocks.11.hook_resid_post, [:]))\n",
      "\n",
      "Metric after removing connection to blocks.10.attn.hook_result [:, :, 2] is 0.0 (and current metric 0.0)\n",
      "Result is 0.0...so removing connection\n",
      "No edge 32906\n",
      "\n",
      "Node: cur_parent=TLACDCInterpNode(blocks.10.attn.hook_result, [:, :, 3]) (self.current_node=TLACDCInterpNode(blocks.11.hook_resid_post, [:]))\n",
      "\n",
      "Metric after removing connection to blocks.10.attn.hook_result [:, :, 3] is 0.0 (and current metric 0.0)\n",
      "Result is 0.0...so removing connection\n",
      "No edge 32905\n",
      "\n",
      "Node: cur_parent=TLACDCInterpNode(blocks.10.attn.hook_result, [:, :, 4]) (self.current_node=TLACDCInterpNode(blocks.11.hook_resid_post, [:]))\n",
      "\n",
      "Metric after removing connection to blocks.10.attn.hook_result [:, :, 4] is 0.0 (and current metric 0.0)\n",
      "Result is 0.0...so removing connection\n",
      "No edge 32904\n",
      "\n",
      "Node: cur_parent=TLACDCInterpNode(blocks.10.attn.hook_result, [:, :, 5]) (self.current_node=TLACDCInterpNode(blocks.11.hook_resid_post, [:]))\n",
      "\n",
      "Metric after removing connection to blocks.10.attn.hook_result [:, :, 5] is 0.0 (and current metric 0.0)\n",
      "Result is 0.0...so removing connection\n",
      "No edge 32903\n",
      "\n",
      "Node: cur_parent=TLACDCInterpNode(blocks.10.attn.hook_result, [:, :, 6]) (self.current_node=TLACDCInterpNode(blocks.11.hook_resid_post, [:]))\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-55-f191bca289fb>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_num_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mexp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtesting\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     show(\n\u001b[1;32m      5\u001b[0m         \u001b[0mexp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcorr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/acdc/TLACDCExperiment.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, early_stop, testing)\u001b[0m\n\u001b[1;32m    625\u001b[0m                     \u001b[0mold_second_metric\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcur_second_metric\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    626\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 627\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_cur_metric\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecalc_edges\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# warning: gives fast evaluation, though edge count is wrong\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    628\u001b[0m                 \u001b[0mevaluated_metric\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcur_metric\u001b[0m \u001b[0;31m# self.metric(self.model(self.ds)) # OK, don't calculate second metric?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    629\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/acdc/TLACDCExperiment.py\u001b[0m in \u001b[0;36mupdate_cur_metric\u001b[0;34m(self, recalc_metric, recalc_edges, initial)\u001b[0m\n\u001b[1;32m    217\u001b[0m             \u001b[0;31m# logits = torch.cat(logits, dim=0)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 219\u001b[0;31m             \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    220\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcur_metric\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetric\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msecond_metric\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformer_lens/HookedEncoder.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, return_type, token_type_ids, one_zero_attention_mask)\u001b[0m\n\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mblock\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblocks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 134\u001b[0;31m             \u001b[0mresid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mblock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madditive_attention_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    135\u001b[0m         \u001b[0mresid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmlm_head\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformer_lens/components.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, resid_pre, additive_attention_mask)\u001b[0m\n\u001b[1;32m   1533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1534\u001b[0m         attn_out = self.hook_attn_out(\n\u001b[0;32m-> 1535\u001b[0;31m             self.attn(\n\u001b[0m\u001b[1;32m   1536\u001b[0m                 \u001b[0mquery_input\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1537\u001b[0m                 \u001b[0mkey_input\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformer_lens/components.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, query_input, key_input, value_input, past_kv_cache_entry, additive_attention_mask, attention_mask)\u001b[0m\n\u001b[1;32m    573\u001b[0m         \u001b[0mpattern\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpattern\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m         \u001b[0mpattern\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpattern\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 575\u001b[0;31m         \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcalculate_z_scores\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpattern\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# [batch, pos, head_index, d_head]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    576\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_attn_result\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    577\u001b[0m             out = (\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformer_lens/components.py\u001b[0m in \u001b[0;36mcalculate_z_scores\u001b[0;34m(self, v, pattern)\u001b[0m\n\u001b[1;32m    681\u001b[0m     ) -> Float[torch.Tensor, \"batch query_pos head_index d_head\"]:\n\u001b[1;32m    682\u001b[0m         z = self.hook_z(\n\u001b[0;32m--> 683\u001b[0;31m             einsum(\n\u001b[0m\u001b[1;32m    684\u001b[0m                 \u001b[0;31m\"\u001b[0m\u001b[0mbatch\u001b[0m \u001b[0mkey_pos\u001b[0m \u001b[0mhead_index\u001b[0m \u001b[0md_head\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    685\u001b[0m                 \u001b[0mbatch\u001b[0m \u001b[0mhead_index\u001b[0m \u001b[0mquery_pos\u001b[0m \u001b[0mkey_pos\u001b[0m \u001b[0;34m->\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/fancy_einsum/__init__.py\u001b[0m in \u001b[0;36meinsum\u001b[0;34m(equation, *operands)\u001b[0m\n\u001b[1;32m    134\u001b[0m     \u001b[0mbackend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moperands\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m     \u001b[0mnew_equation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_equation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mequation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 136\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meinsum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_equation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0moperands\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/fancy_einsum/__init__.py\u001b[0m in \u001b[0;36meinsum\u001b[0;34m(self, equation, *operands)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0meinsum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mequation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0moperands\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meinsum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mequation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0moperands\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/functional.py\u001b[0m in \u001b[0;36meinsum\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m    376\u001b[0m         \u001b[0;31m# the path for contracting 0 or 1 time(s) is already optimized\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    377\u001b[0m         \u001b[0;31m# or the user has disabled using opt_einsum\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 378\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_VF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meinsum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mequation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moperands\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[attr-defined]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    379\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    380\u001b[0m     \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i in range(args.max_num_epochs):\n",
    "    exp.step(testing=False)\n",
    "\n",
    "    show(\n",
    "        exp.corr,\n",
    "        f\"ims/img_new_{i+1}.png\",\n",
    "        show_full_index=False,\n",
    "    )\n",
    "\n",
    "    if IN_COLAB or ipython is not None:\n",
    "        # so long as we're not running this as a script, show the image!\n",
    "        display(Image(f\"ims/img_new_{i+1}.png\"))\n",
    "\n",
    "    print(i, \"-\" * 50)\n",
    "    print(exp.count_no_edges())\n",
    "\n",
    "    if i == 0:\n",
    "        exp.save_edges(\"edges.pkl\")\n",
    "\n",
    "    if exp.current_node is None or SINGLE_STEP:\n",
    "        break\n",
    "\n",
    "exp.save_edges(\"another_final_edges.pkl\")\n",
    "\n",
    "if USING_WANDB:\n",
    "    edges_fname = f\"edges.pth\"\n",
    "    exp.save_edges(edges_fname)\n",
    "    artifact = wandb.Artifact(edges_fname, type=\"dataset\")\n",
    "    artifact.add_file(edges_fname)\n",
    "    wandb.log_artifact(artifact)\n",
    "    os.remove(edges_fname)\n",
    "    wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "slt7ZpqY8AfK",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 532,
     "referenced_widgets": [
      "4c13a0569305445bbc700e7222e36146",
      "6b641f8ec8c147bf810558ade54a3eee",
      "4308ff58adfa4038ba16360195620155",
      "1fc0f708948240f986436589f4003637",
      "9f8cd44dd3dc4e18a86f660bccd5f1cf",
      "e319a286978f4de0a76db9a22949eca5",
      "fc8cd74fe26e49a39d3fd00a88989423",
      "83be4263af5b425ab22385f930b403c2"
     ]
    },
    "id": "slt7ZpqY8AfK",
    "outputId": "00da5e5c-35c3-4192-e6ec-3a669a4f5153"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c13a0569305445bbc700e7222e36146",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.094 MB of 0.157 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=0.595011"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>cur_metric</td><td></td></tr><tr><td>experiment.cur_metric</td><td></td></tr><tr><td>num_edges</td><td></td></tr><tr><td>num_edges_total</td><td></td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>cur_metric</td><td>0.0</td></tr><tr><td>experiment.cur_metric</td><td>0.0</td></tr><tr><td>num_edges</td><td>27247</td></tr><tr><td>num_edges_total</td><td>32766</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">Sat_Apr_27_18_58_32_2024_0.71</strong> at: <a href='https://wandb.ai/andresvanschel/acdc/runs/hb5b5zv3' target=\"_blank\">https://wandb.ai/andresvanschel/acdc/runs/hb5b5zv3</a><br/>Synced 5 W&B file(s), 7 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>/tmp/wandb/wandb/run-20240427_185847-hb5b5zv3/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3511120b",
   "metadata": {
    "id": "3511120b"
   },
   "source": [
    "<h2>Save the final subgraph of the model</h2>\n",
    "<p>There are more than `exp.count_no_edges()` here because we include some \"placeholder\" edges needed to make ACDC work that don't actually matter</p>\n",
    "<p>Also note that the final image has more than 12 edges, because the edges from a0.0_q and a0.0_k are not connected to the input</p>\n",
    "<p>We recover minimal induction machinery! `embed -> a0.0_v -> a1.6k`</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "140b667d",
   "metadata": {
    "id": "140b667d",
    "outputId": "5d380f23-6546-47c7-eeb0-573129d6b1a3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([(('blocks.1.hook_resid_post',\n",
       "               (None,),\n",
       "               'blocks.1.attn.hook_result',\n",
       "               (None, None, 6)),\n",
       "              True),\n",
       "             (('blocks.1.hook_resid_post',\n",
       "               (None,),\n",
       "               'blocks.0.hook_resid_pre',\n",
       "               (None,)),\n",
       "              True),\n",
       "             (('blocks.1.attn.hook_result',\n",
       "               (None, None, 6),\n",
       "               'blocks.1.attn.hook_q',\n",
       "               (None, None, 6)),\n",
       "              True),\n",
       "             (('blocks.1.attn.hook_result',\n",
       "               (None, None, 6),\n",
       "               'blocks.1.attn.hook_k',\n",
       "               (None, None, 6)),\n",
       "              True),\n",
       "             (('blocks.1.attn.hook_result',\n",
       "               (None, None, 6),\n",
       "               'blocks.1.attn.hook_v',\n",
       "               (None, None, 6)),\n",
       "              True),\n",
       "             (('blocks.1.attn.hook_q',\n",
       "               (None, None, 6),\n",
       "               'blocks.1.hook_q_input',\n",
       "               (None, None, 6)),\n",
       "              True),\n",
       "             (('blocks.1.attn.hook_k',\n",
       "               (None, None, 6),\n",
       "               'blocks.1.hook_k_input',\n",
       "               (None, None, 6)),\n",
       "              True),\n",
       "             (('blocks.1.attn.hook_v',\n",
       "               (None, None, 6),\n",
       "               'blocks.1.hook_v_input',\n",
       "               (None, None, 6)),\n",
       "              True),\n",
       "             (('blocks.1.hook_q_input',\n",
       "               (None, None, 6),\n",
       "               'blocks.0.hook_resid_pre',\n",
       "               (None,)),\n",
       "              True),\n",
       "             (('blocks.1.hook_k_input',\n",
       "               (None, None, 6),\n",
       "               'blocks.0.attn.hook_result',\n",
       "               (None, None, 0)),\n",
       "              True),\n",
       "             (('blocks.1.hook_v_input',\n",
       "               (None, None, 6),\n",
       "               'blocks.0.hook_resid_pre',\n",
       "               (None,)),\n",
       "              True),\n",
       "             (('blocks.0.attn.hook_result',\n",
       "               (None, None, 0),\n",
       "               'blocks.0.attn.hook_q',\n",
       "               (None, None, 0)),\n",
       "              True),\n",
       "             (('blocks.0.attn.hook_result',\n",
       "               (None, None, 0),\n",
       "               'blocks.0.attn.hook_k',\n",
       "               (None, None, 0)),\n",
       "              True),\n",
       "             (('blocks.0.attn.hook_result',\n",
       "               (None, None, 0),\n",
       "               'blocks.0.attn.hook_v',\n",
       "               (None, None, 0)),\n",
       "              True),\n",
       "             (('blocks.0.attn.hook_v',\n",
       "               (None, None, 0),\n",
       "               'blocks.0.hook_v_input',\n",
       "               (None, None, 0)),\n",
       "              True),\n",
       "             (('blocks.0.hook_v_input',\n",
       "               (None, None, 0),\n",
       "               'blocks.0.hook_resid_pre',\n",
       "               (None,)),\n",
       "              True)])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp.save_subgraph(\n",
    "    return_it=True,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 15.193446,
   "end_time": "2023-08-14T00:37:11.439598",
   "environment_variables": {},
   "exception": null,
   "input_path": "notebooks/_converted/main_demo.ipynb",
   "output_path": "notebooks/colabs/ACDC_Main_Demo.ipynb",
   "parameters": {},
   "start_time": "2023-08-14T00:36:56.246152",
   "version": "2.4.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "01b21ab6851a498189fc5112bdde0d84": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b82d99f2b6274234961728058fe21b70",
      "placeholder": "",
      "style": "IPY_MODEL_58c56bdd44d34e919fbc8912d56e9826",
      "value": "Map:100%"
     }
    },
    "1c8c04d2d5af4f3ea357658d917a0f53": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4f847958e54d432696ef90260fb69efb",
      "placeholder": "",
      "style": "IPY_MODEL_9fc3fcdce1a04843ad2d0c48f90e354c",
      "value": "20/20[00:00&lt;00:00,757.44examples/s]"
     }
    },
    "1fc0f708948240f986436589f4003637": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "24347ef554574e9fa8ef4f59ebfd9601": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3f9414296baf44b0bf601c16a3e1bca8": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4308ff58adfa4038ba16360195620155": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_fc8cd74fe26e49a39d3fd00a88989423",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_83be4263af5b425ab22385f930b403c2",
      "value": 0.5950114230655024
     }
    },
    "44e291f5c9474bb7ba9e093039ebe683": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "VBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "VBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "VBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_4ece0a17b74e48cda581bc50db67cae1",
       "IPY_MODEL_e5f088bc64e442bcb1a952ccfd7d5e6d"
      ],
      "layout": "IPY_MODEL_24347ef554574e9fa8ef4f59ebfd9601"
     }
    },
    "4c13a0569305445bbc700e7222e36146": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "VBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "VBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "VBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_6b641f8ec8c147bf810558ade54a3eee",
       "IPY_MODEL_4308ff58adfa4038ba16360195620155"
      ],
      "layout": "IPY_MODEL_1fc0f708948240f986436589f4003637"
     }
    },
    "4ece0a17b74e48cda581bc50db67cae1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "LabelModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "LabelModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "LabelView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ab22f4e3d96f409ba3d2f556c8e98c6a",
      "placeholder": "",
      "style": "IPY_MODEL_801fd09a08044efeacd71458ef758a9f",
      "value": "0.094 MB of 0.094 MB uploaded (0.000 MB deduped)\r"
     }
    },
    "4f847958e54d432696ef90260fb69efb": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "58c56bdd44d34e919fbc8912d56e9826": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "6b641f8ec8c147bf810558ade54a3eee": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "LabelModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "LabelModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "LabelView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9f8cd44dd3dc4e18a86f660bccd5f1cf",
      "placeholder": "",
      "style": "IPY_MODEL_e319a286978f4de0a76db9a22949eca5",
      "value": "0.094 MB of 0.157 MB uploaded (0.000 MB deduped)\r"
     }
    },
    "71127168c8b54f7da6fe9a5ff18af04e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d7fe10bc29234a2e8fbe3e33a330639d",
      "max": 20,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_783faf6175604e53b02327d0acb582b9",
      "value": 20
     }
    },
    "783faf6175604e53b02327d0acb582b9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "801fd09a08044efeacd71458ef758a9f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "836d6affb51f436fa5bf94d0ae3c1129": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "83be4263af5b425ab22385f930b403c2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "95886397324b4670bd62994f8cba7561": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_01b21ab6851a498189fc5112bdde0d84",
       "IPY_MODEL_71127168c8b54f7da6fe9a5ff18af04e",
       "IPY_MODEL_1c8c04d2d5af4f3ea357658d917a0f53"
      ],
      "layout": "IPY_MODEL_aa992dbd1b804405acdbddb0184d35f4"
     }
    },
    "9f8cd44dd3dc4e18a86f660bccd5f1cf": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9fc3fcdce1a04843ad2d0c48f90e354c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "aa992dbd1b804405acdbddb0184d35f4": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ab22f4e3d96f409ba3d2f556c8e98c6a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b82d99f2b6274234961728058fe21b70": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d7fe10bc29234a2e8fbe3e33a330639d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e319a286978f4de0a76db9a22949eca5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "e5f088bc64e442bcb1a952ccfd7d5e6d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3f9414296baf44b0bf601c16a3e1bca8",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_836d6affb51f436fa5bf94d0ae3c1129",
      "value": 1
     }
    },
    "fc8cd74fe26e49a39d3fd00a88989423": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
